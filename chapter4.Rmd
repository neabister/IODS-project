---
output:
  html_document:
    css: styles.css
---

#Chapter 4: Clustering {.tabset}

In this exercise I analyze `Boston`data set available in `MASS` package. 


###More information on Boston data set:  

<https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/Boston.html>

##Loading MASS and Boston data set

`Boston` data set contains information from 506 housing observation (rows) with 14 different variables (columns).

```{r, message=FALSE}
library(MASS)
data('Boston')

str(Boston)
summary(Boston)


```

##Visualize and summarize data

Nice corrplot modification examples <https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html>

```{r, message=FALSE}
library(corrplot)
library(RColorBrewer)
#pairs(Boston)

correlations <- cor(Boston)
round(correlations, digits = 2)
colors <- brewer.pal(n = 9, name = "Pastel1")
signf_test <- cor.mtest(Boston, conf.level = .95)

corrplot(correlations, type = 'upper', method = 'ellipse', order = "hclust", col = brewer.pal(n = 8, name = "PiYG"), bg = colors[length(colors)], 
         p.mat = signf_test$p, insig = 'p-value', sig.level = .05, tl.col = "black", tl.srt = 90)

```

Above `corrplot` shows negative correlations in pink and positive correlations in green. Narrowness of `method = 'ellipse'` indicates how high correlation is. For non-significant correlations (p>0.05), p-values are shown.  

From the graph it can be observed that most of the variables correlate significantly with others. Only few pairs are not significantly correlated.

##Scale variables and categorical crimes

To be able to accurately classify the data, variable values need to be scaled so that all variables have a mean value of 0. It is done as follows (when all variables are numerical, as expected for classification analysis):

```{r}
scaled <- as.data.frame(scale(Boston))
class(scaled)
str(scaled)
summary(scaled)

```

Next, `crim` is cut to categorical variable according to quantiles to be able to later use it to train the model to predict the right crime rate class of an observation based on other variables.

```{r}
bins = quantile(scaled$crim)

crime <- cut(scaled$crim, breaks = bins, label = c('low', 'med_low', 'med_high', 'high'), include.lowest = TRUE)

#count table for each category level
table(crime)

#replace original crim with categorical crime variable

scaled <- dplyr::select(scaled, -crim)
scaled <- data.frame(scaled, crime)
head(scaled)

```

##Divide data for training and test sets

To be able to evaluate how well our model is predicting crime rate, I want to separate small fraction of the data (20%) for testing it, so it will not be used for training the model. Observations are selected randomly below for training or test sets.

```{r}
random_test_rows <- sample(nrow(scaled), size = nrow(scaled) * 0.2)

test_set <- scaled[random_test_rows, ]
train_set <- scaled[-random_test_rows, ]

#Check that resulting dfs are as should
dim(test_set)
dim(train_set)

```

##Fitting linear discriminant analysis for crimes

Fitting classification model with `lda()` function using `crimes` as a categorical variable and all other (continuous) variables as predicting variables.

```{r}
lda_fit <- lda(crime ~ ., data = train_set)
lda_fit

```

###Visualization of model

Using `ggsci` color palette and `ggord` package to visualize `lda_fit`. To install `ggord` package from Github, I use `install_github` function from `devtools` package.

```{r, message=FALSE, warning=FALSE}

#Convert crime factor levels to numeric to plot in different colors
crime_levels <- as.numeric(train_set$crime)

#I hate the default colors of the plot, so I'm using ggsci package palettes instead
#Good source for color palettes https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/
library(ggsci)
library(devtools)
install_github("fawda123/ggord")
library(ggord)

cols <- pal_aaas()(4)

#color vector corresponding to levels of crimes in lda
cols_crimes <- cols[crime_levels]

#Plot with nicer colors

ggord(lda_fit, train_set$crime, poly = FALSE, arrow=.3, veclsz = .5, vec_ext = 4, size=1, cols = cols)

```

There are so many variables in the model, that the arrows look a bit messy. However, it is easy to see still which variables affect the classification most (zn, rad, nox). This `ggord` package was very nice and easy to use. You can see that the model does not classify crime rates perfectly but I would say it does pretty good job distinguishing `high` crime rate from others in `train_set`.



