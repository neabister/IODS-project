---
output:
  html_document:
    css: styles.css
---

#Chapter 3: Logistic regression analysis to predict alcohol consumption {.tabset}

In this exercise I analyze preprocessed data.  

###Link to preprocessing R script:  
<https://github.com/neabister/IODS-project/blob/master/data/create_alc.R>
  
###Link to original data:  

<https://archive.ics.uci.edu/ml/datasets/Student+Performance>
  

###Original data and preprocessing  

Original data sets consist of students from Math (1) and Portuguese language (2) classes who answered to several questions to assess their economical, family and activity status, and variables related to studying and alcoholc consumption. In data pre-processing, individual students were identified based on combination of 13 variables and only students present in both datasets were selected.  

Alcohol use was evaluated numerically, separately for weekdays and weekends. To quantify overall consumption, average for these 2 variables was calculated into column `alc_use`. To group students into high and low alcohol use, threshold of 2 was applied to identify students with high alcohol use in a column `high_use`.

###Data analysis

##Read and explore the data

```{r}
data <- read.csv('data/create_alc.csv', sep=',')
head(data)
dim(data)
str(data)


```

Dataset has 35 variables and 382 observations (students). Data describes several background informations collected from students attending both math and portuguese language.

##Personal hypothesis prior to analysis

Four interesting variables that could predict high alcohol consumption:

1.  absences
    + High alcohol use could lead to more absences
2.  Pstatus (together, apart)
    + Perhaps problematic alcohol use could be more likely in broken families
3.  sex
    + Male gender could predispose to high alcohol use
4.  goout
    + Could lead to higher alcohol use (being problematic use or not) because students going out often involves alcohol
    
```{r}
interesting_variables <- c('absences', 'Pstatus', 'sex', 'goout', 'high_use')
```

##Graphical data exploration & Summary statistics

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)

interesting <- select(data, one_of(interesting_variables))
gather(interesting) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()

sex_plot <- ggplot(interesting, aes(sex, fill = high_use))
p1 <- sex_plot + geom_bar(position = 'dodge') + ggtitle('Sex')

Pstatus_plot <- ggplot(interesting, aes(Pstatus, fill = high_use))
p2 <- Pstatus_plot + geom_bar(position = 'dodge') + ggtitle('Pstatus')

absences_plot <- ggplot(interesting, aes(x = high_use, y = absences, col = sex))
p3 <- absences_plot + geom_boxplot() + ylab("Number of absences") + ggtitle('Absences')

goout_plot <- ggplot(interesting, aes(x = high_use, y = goout, col = sex))
p4 <- goout_plot + geom_boxplot() + ylab("Going out") + ggtitle('Go out')

grid.arrange(p1, p2, p3, p4, nrow=2)

```

Findings:  
1.  *Sex*: Larger fraction of male students have high alcohol consumption than female. Initial hypothesis would hold true.  
2.  *Parents together/separated*: Most of the parents are together. Hard to say from the plot if fraction of student with high alcohol consumption would be found in separated families (effect is not as dramatic as with sex).  
3.  *Absences*: Data is quite spread especially among female students. Trend of more absences in high alcohol use is clearer in males.  
4.  *Go out*: Again positive correlation between going out and high alcohol use, which again clearer in male students.  

My hypotheses are not completely useless at least.

##Summary statistics by group

Below is table showing mean values for `absences` and `goout` between low and high alcohol use, separately for male and female students.
It seems that both measured variables have higher mean value in high alcohol use group than in low use, this is true for both sexes. However, difference may not be statistically significant (based on how plots look above). Anyway, these variables may have some predictive power for logistic model.

```{r}

interesting %>% group_by(sex, high_use) %>% summarise(count = n(), mean_absences = mean(absences), mean_goout = mean(goout))


```

##Logistic regression fitting

```{r}
model1 <- glm(high_use ~ sex + Pstatus + absences + goout, data = interesting, family = 'binomial')

summary(model1)
coef(model1)

```

1.  Sex, male: positive effect on high_use  
2.  Pstatus, together: non-significant effect on high_use  
3.  Absences: positive effect on high_use  
4.  Go out: positive effect on high_use  
  
Deviance = measure of goodness of fit, higher number indicates worse fit  
  - Null deviance = When only intercept is included to the model  
  - Residual deviance = Includes all variables in the model -> Residual deviance is a bit lower than null 

AIC = compare different models, lower is better

##Odds ratio and confidence intervals

```{r}
OR <- coef(model1) %>% exp
CI <- confint(model1) %>% exp

cbind(OR, CI)

```

Odds ratio >1 implies increased likelyhood that student's consumption of alcohol is high. If 1 is included in the CI, it means that interval spans from below 1 to more than 1 and the variable has no predictive power on dependent variable. Thus, from CI and OR table can be concluded that male sex and going out increase the likelyhood that person's alcohol consumption is high. Absences seem to have small effect whereas Pstatus does not have effect on alcohol consumtpion (also seen from model summary where this variable is the only one that is not significant).

##Analysis of predictive power

Since Pstatus was not significant variable, I will fit a new model (`model2`) without it and evaluate how well it predicts high_use in this same data set.
First I am calculating probabilities of high_use with the `model2` and appending this information in dataframe `interesting` that contains all my interesting variables. Additionally, I am generating a column for prediction of high_use that gets value `TRUE` if probability is >0.5 and `FALSE` if <0.5.


```{r}
model2 <- glm(high_use ~ sex + absences + goout, data = interesting, family = 'binomial')

probabilities <- predict(model2, type = 'response')

interesting <- mutate(interesting, probability = probabilities)

interesting <- mutate(interesting, predicted_high_use = probability > 0.5)

head(interesting)

```

To assess model's prediction power, I am checking how often prediction and real values are matching

```{r}
table(high_use = interesting$high_use, prediction = interesting$predicted_high_use)
```

###Visualizing 

```{r}
g <- ggplot(interesting, aes(x = probability, y = high_use, col = predicted_high_use))
g + geom_point()

```

```{r}
# tabulate the target variable versus the predictions
table(high_use = interesting$high_use, prediction = interesting$predicted_high_use) %>% prop.table %>% addmargins

sensitivity <- 0.1283 / 0.2984 * 100
specificity <- 0.6623 / 0.7016 * 100

```

Model sensitivity is `r sensitivity` % and specificity `r specificity` %, meaning that it is not predicting false positives too easily but is more vulnerable to miss true positives (predicts more false negatives).

##Step-wise best model selection

Since 4 interesting variables were chosen quite randomly in the first place, I want to explore options to find the best model more automatically. Here I will use `step()` function to test models with different variables included.

```{r}
#select all except Dalc and Walc
variables_for_step <- dplyr::select(data, -Dalc, -Walc)
#select independent variables (all except alc_use which are two last columns)
names_variables <- colnames(variables_for_step)
variables_used <- names_variables[seq_len(length(names_variables)-2)]

#Constructing formula to use for step-wise model search
Formula <- formula(paste("high_use ~ ", paste(variables_used, collapse=" + ")))

```

Running `step()` function with build `Formula`. It takes some time and output is very long so output is hidden.

```{r, results='hide'}
model3 <- glm(Formula, data = variables_for_step, family = 'binomial')
step(model3, direction = "backward")

```

Below is the function with lowest AIC found by `step()`

```{r}
#Final best fit variables
model_best <- glm(high_use ~ sex + address + Fjob + traveltime + studytime + paid + activities + famrel + freetime + goout + absences, family = "binomial",
    data = variables_for_step)

```

##Compare 3 logistic models

I have fitted three models: `model1`, `model3`, `model_best` and wanted to compare these to each other with `anova` and collect model parameters in one `table`.

```{r}
anova <- anova(model_best, model1, model2)
anova

```

```{r, results='hide', message=FALSE, warning=FALSE}
library(stargazer)
table <- stargazer(model_best, model1, model2, title='Comparison of logistic regression models', type="html", align = TRUE)

```

`r paste(table, collapse = "")`

Based on Residual Deviances and AIC, `best_model` would be the best fit. However, it is quite complex including 15 variables so I want to see how much better it actually performs.  
Predicting `high_use` with 3 models:  

```{r}


probabilities1 <- predict(model1, type = 'response')
probabilities2 <- predict(model2, type = 'response')
probabilities_model_best <- predict(model_best, type = 'response') 

predictions_3_models <- mutate(variables_for_step, probability_model1 = probabilities1, probability_model2 = probabilities2, probability_best = probabilities_model_best)

predictions_3_models <- mutate(predictions_3_models, predicted_high_use_m1 = probability_model1 > 0.5, predicted_high_use_m2 = probability_model2 > 0.5, 
                               predicted_high_use_best = probability_best > 0.5)

```

###2x2 tables for models

```{r}

model1_table <- table(high_use = predictions_3_models$high_use, prediction_model1 = predictions_3_models$predicted_high_use_m1) %>% prop.table %>% addmargins
model2_table <- table(high_use = predictions_3_models$high_use, prediction_model2 = predictions_3_models$predicted_high_use_m2) %>% prop.table %>% addmargins
best_model_table <- table(high_use = predictions_3_models$high_use, prediction_best_model = predictions_3_models$predicted_high_use_best) %>% prop.table %>% addmargins

model1_table
model2_table
best_model_table

# Calculate sensitivity and specificity for all models 
sensitivity_m1 <- 0.1283 / 0.2984 * 100
specificity_m1 <- 0.6623 / 0.7016 * 100


sensitivity_m2 <- 0.1283 / 0.2984 * 100
specificity_m2 <- 0.6623 / 0.7016 * 100

sensitivity_best <- 0.1518 / 0.2984 * 100
specificity_best <- 0.6545 / 0.7016 * 100

#Collect accuracy parameters in one df
model_accuracy <- data.frame("Model" = c('Model 1', 'Model 2', 'Best model'), "Sensitivity" = c(sensitivity_m1, sensitivity_m2, sensitivity_best), "Specificity" = c(specificity_m1, specificity_m2, specificity_best))

print(model_accuracy, digits = 3)

```

###Graphical visualization of models

```{r, message=FALSE, warning=FALSE}
#Nice examples for plot arrangements http://www.sthda.com/english/wiki/wiki.php?id_contents=7930
library(cowplot)
m1_plot <- ggplot(predictions_3_models, aes(x = probability_model1, y = high_use, col = predicted_high_use_m1))
m2_plot <- ggplot(predictions_3_models, aes(x = probability_model2, y = high_use, col = predicted_high_use_m2))
best_plot <- ggplot(predictions_3_models, aes(x = probability_best, y = high_use, col = predicted_high_use_best))

g1 <- m1_plot + geom_point() + ggtitle('Model 1')
g2 <- m2_plot + geom_point() + ggtitle('Model 2')
g3 <- best_plot + geom_point() + ggtitle('Best model')

plot_grid(g1, g2, g3, labels=c("A", "B", "C"), ncol = 1, nrow = 3)

```

##Conclusions

Selection of a model is always a trade of between specificity, sensitivity and complexity of the model. If we allow more complex model, I would select `best_model` because of significantly improved **sensitivity** compared to other models, even if there is slight drop in **specificity**.